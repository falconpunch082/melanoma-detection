{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03c61c45-b31e-4b8d-bdd1-5128cc369203",
   "metadata": {},
   "source": [
    "# Training, Validation and Testing Image Data Partition and Preprocessing Notebook\n",
    "\n",
    "The purpose of this notebook is to show how the training, validation and testing preprocessed image datasets were created from a raw, unprocessed dataset.\n",
    "\n",
    "This notebook comprises of two parts: the splitting of unprocessed data into 3 parts (training, validation and testing), and the preprocessing process similar to the SPARK preprocessing script."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86cb245d-9a19-41f7-858f-1efcaf3952e2",
   "metadata": {},
   "source": [
    "## Image Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ade13be-d14b-4632-87a2-0d489baa8209",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 41924 files [24:27, 28.58 files/s]\n"
     ]
    }
   ],
   "source": [
    "# Importing splitfolders library for easy splitting\n",
    "import splitfolders\n",
    "\n",
    "# Creating training, validation, and testing datasets from 'raw_data' folder to 'img_data' folder.\n",
    "# The ratio of images inside the training, validation and testing datasets is 90% : 7.5% : 2.5%\n",
    "splitfolders.ratio('raw_data', output=\"img_data\", seed=1337, ratio=(0.9,0.075,0.025))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac824612-e431-4c16-9a4f-52135dfc6eb8",
   "metadata": {},
   "source": [
    "## Image Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49b35ea2-4323-4468-a458-4f719282acce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing relevant packages\n",
    "from scipy import ndimage, misc\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage import io, color, exposure\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d75ab1ba-6101-4526-a1c2-507191facb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining paths\n",
    "# Input folders\n",
    "train0_path = \"img_data/train/0\"\n",
    "train1_path = \"img_data/train/1\"\n",
    "val0_path = \"img_data/val/0\"\n",
    "val1_path = \"img_data/val/1\"\n",
    "test0_path = \"img_data/test/0\"\n",
    "test1_path = \"img_data/test/1\"\n",
    "\n",
    "# Output folders\n",
    "ptrain0_path = \"processed/train/0\"\n",
    "ptrain1_path = \"processed/train/1\"\n",
    "pval0_path = \"processed/val/0\"\n",
    "pval1_path = \"processed/val/1\"\n",
    "ptest0_path = \"processed/test/0\"\n",
    "ptest1_path = \"processed/test/1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f9f5818-df26-44c3-b70c-29c2ffd8b2ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['img_data/train/0', 'processed/train/0'],\n",
       " ['img_data/train/1', 'processed/train/1'],\n",
       " ['img_data/val/0', 'processed/val/0'],\n",
       " ['img_data/val/1', 'processed/val/1'],\n",
       " ['img_data/test/0', 'processed/test/0'],\n",
       " ['img_data/test/1', 'processed/test/1']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating list of paths\n",
    "path_list = [[train0_path, ptrain0_path], [train1_path, ptrain1_path], [val0_path, pval0_path], [val1_path, pval1_path], [test0_path, ptest0_path], [test1_path, ptest1_path]]\n",
    "\n",
    "path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aba25502-c10a-4d9a-9e41-7231081f79a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each input path (and output path) in the list of paths... \n",
    "for in_path, out_path in path_list:\n",
    "        # and for each image in the input folder in question...\n",
    "        for image_path in os.listdir(in_path):\n",
    "            # Loading in image\n",
    "            img = Image.open(in_path + \"/\" + image_path)\n",
    "\n",
    "            '''\n",
    "            Section 1: Translating image into array\n",
    "            '''\n",
    "            \n",
    "            # Resize the image to a consistent size (e.g., 224x224)\n",
    "            img = img.resize((300, 300))\n",
    "        \n",
    "            # Convert the image to a NumPy array\n",
    "            img_array = np.array(img)\n",
    "            \n",
    "            # Normalize pixel values\n",
    "            img_array = cv2.normalize(img_array, None, 255, 0, cv2.NORM_MINMAX, cv2.CV_8U)\n",
    "\n",
    "            '''\n",
    "            Section 2: Creating the mask to remove unnecessary features like healthy skin and hair.\n",
    "            Hair is first removed with the DullRazor algorithm, resulting in an image which is then used\n",
    "            to create a mask highlighting the skinmark.\n",
    "            '''\n",
    "            \n",
    "            # Converting RGB picture to greyscale for hair removal DullRazor algorithm\n",
    "            img_gc = color.rgb2gray(img_array)\n",
    "\n",
    "            # DullRazor algorithm starts here\n",
    "            #Black hat filter\n",
    "            kernel = cv2.getStructuringElement(1,(9,9)) \n",
    "            blackhat = cv2.morphologyEx(img_gc, cv2.MORPH_BLACKHAT, kernel)\n",
    "            \n",
    "            #Gaussian filter\n",
    "            bhg= cv2.GaussianBlur(blackhat,(3,3),cv2.BORDER_DEFAULT)\n",
    "\n",
    "            #Masking hair\n",
    "            ret, mask = cv2.threshold(bhg,0.03,255,cv2.THRESH_BINARY)\n",
    "            \n",
    "            # Normalise mask\n",
    "            mask = cv2.normalize(mask, None, 255, 0, cv2.NORM_MINMAX, cv2.CV_8U)\n",
    "            \n",
    "            #Replace pixels of the mask\n",
    "            dst = cv2.inpaint(img_array, mask, 6, cv2.INPAINT_TELEA)\n",
    "            # DullRazor algorithm ends here\n",
    "\n",
    "            # Adjusting exposure\n",
    "            img_ex1 = exposure.adjust_log(dst)\n",
    "\n",
    "            p2, p98 = np.percentile(img_ex1, (2, 98))\n",
    "            img_ex2 = exposure.rescale_intensity(img_ex1, in_range=(p2, p98))\n",
    "\n",
    "            # Converting cleaned photo into greyscale for thresholding/segmentation\n",
    "            img_ex2 = color.rgb2gray(img_ex2)\n",
    "    \n",
    "            # Global thresholding with Otsu\n",
    "            thresh = threshold_otsu(img_ex2)\n",
    "            \n",
    "            # Creating threshold image\n",
    "            img_t = img_ex2 <= thresh\n",
    "    \n",
    "            # Creating mask using threshold image\n",
    "            # Value 0 as black and white photo used\n",
    "            mask = np.where(img_t >= 0, img_t, 0)\n",
    "    \n",
    "            '''\n",
    "            Section 3: Creating the final processed photo by only including parts of img_array that is highlighted by the mask.\n",
    "            '''\n",
    "            \n",
    "            # Nested for loop for each 'row' of img\n",
    "            for h in range(mask.shape[0]):\n",
    "              # For each 'column' of img\n",
    "                for w in range(mask.shape[1]):\n",
    "                  # If the pixel chosen from the mask is white, add in the pixel from the original image\n",
    "                  # Otherwise, discard/make pixel black\n",
    "                    if mask[h][w] == 0:\n",
    "                        for i in range(3):\n",
    "                            img_array[h][w][i] = 0\n",
    "                    else:\n",
    "                        continue\n",
    "        \n",
    "            # Creating full output path and saving the file to disk\n",
    "            fullpath = out_path + '/processed_' + image_path\n",
    "            matplotlib.image.imsave(fullpath, img_array)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
